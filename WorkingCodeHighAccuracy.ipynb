{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KarthikeyanNatarajan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KarthikeyanNatarajan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\KarthikeyanNatarajan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import string\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "import urllib\n",
    "import gzip\n",
    "\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "import pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanString(review,stopWords):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    returnString = \"\"\n",
    "    sentence_token = tokenize.sent_tokenize(review)\n",
    "    idx_list = []\n",
    "    for j in range(len(sentence_token)):\n",
    "        single_sentence = tokenize.word_tokenize(sentence_token[j])\n",
    "        sentences_filtered = [(idx,lemmatizer.lemmatize(w.lower())) for idx,w in enumerate(single_sentence) \n",
    "                              if w.lower() not in stopWords and w.isalnum()]\n",
    "        idx_list.append([x[0] for x in sentences_filtered])\n",
    "        word_list = [x[1] for x in sentences_filtered]\n",
    "        returnString = returnString + ' '.join(word_list) + ' . '\n",
    "    \n",
    "    return returnString, idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(dataframe, column_name, training_split = 0.6, validation_split = 0.2, test_split = 0.2):\n",
    "    \"\"\"\n",
    "    Splits a pandas dataframe into trainingset, validationset and testset in specified ratio.\n",
    "    All sets are balanced, which means they have the same ratio for each categorie as the full set.\n",
    "    Input:   dataframe        - Pandas Dataframe, should include a column for data and one for categories\n",
    "             column_name      - Name of dataframe column which contains the categorical output values\n",
    "             training_split   - from ]0,1[, default = 0.6\n",
    "             validation_split - from ]0,1[, default = 0.2        \n",
    "             test_split       - from ]0,1[, default = 0.2\n",
    "                                Sum of all splits need to be 1\n",
    "    Output:  train            - Pandas DataFrame of trainset\n",
    "             validation       - Pandas DataFrame of validationset\n",
    "             test             - Pandas DataFrame of testset\n",
    "    \"\"\"\n",
    "    if training_split + validation_split + test_split != 1.0:\n",
    "        raise ValueError('Split paramter sum should be 1.0')\n",
    "        \n",
    "    total = len(dataframe.index)\n",
    " \n",
    "    train = dataframe.reset_index().groupby(column_name).apply(lambda x: x.sample(frac=training_split))\\\n",
    "    .reset_index(drop=True).set_index('index')\n",
    "    train = train.sample(frac=1)\n",
    "    temp_df = dataframe.drop(train.index)\n",
    "    validation = temp_df.reset_index().groupby(column_name)\\\n",
    "    .apply(lambda x: x.sample(frac=validation_split/(test_split+validation_split)))\\\n",
    "           .reset_index(drop=True).set_index('index')\n",
    "    validation = validation.sample(frac=1)\n",
    "    test = temp_df.drop(validation.index)\n",
    "    test = test.sample(frac=1)\n",
    "    \n",
    "    print('Total: ', len(dataframe))\n",
    "    print('Training: ', len(train), ', Percentage: ', len(train)/len(dataframe))\n",
    "    print('Validation: ', len(validation), ', Percentage: ', len(validation)/len(dataframe))\n",
    "    print('Test:', len(test), ', Percentage: ', len(test)/len(dataframe))\n",
    "\n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=pd.read_csv('PythonQuestions.csv',encoding =  \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=stats.dropna(subset=[\"Question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "stats[\"Sub_Topic_Code\"] = labelEncoder.fit_transform(stats[\"Sub_Topic_Code\"])\n",
    "stats = stats.rename(columns={'Sub_Topic_Code': 'Category', 'Question': 'Text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=stats.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 340 articles cleaned.\r",
      "2 of 340 articles cleaned.\r",
      "3 of 340 articles cleaned.\r",
      "4 of 340 articles cleaned.\r",
      "5 of 340 articles cleaned.\r",
      "6 of 340 articles cleaned.\r",
      "7 of 340 articles cleaned.\r",
      "8 of 340 articles cleaned.\r",
      "9 of 340 articles cleaned.\r",
      "10 of 340 articles cleaned.\r",
      "11 of 340 articles cleaned.\r",
      "12 of 340 articles cleaned.\r",
      "13 of 340 articles cleaned.\r",
      "14 of 340 articles cleaned.\r",
      "15 of 340 articles cleaned.\r",
      "16 of 340 articles cleaned.\r",
      "17 of 340 articles cleaned.\r",
      "18 of 340 articles cleaned.\r",
      "19 of 340 articles cleaned.\r",
      "20 of 340 articles cleaned.\r",
      "21 of 340 articles cleaned.\r",
      "22 of 340 articles cleaned.\r",
      "23 of 340 articles cleaned.\r",
      "24 of 340 articles cleaned.\r",
      "25 of 340 articles cleaned.\r",
      "26 of 340 articles cleaned.\r",
      "27 of 340 articles cleaned.\r",
      "28 of 340 articles cleaned.\r",
      "29 of 340 articles cleaned.\r",
      "30 of 340 articles cleaned.\r",
      "31 of 340 articles cleaned.\r",
      "32 of 340 articles cleaned.\r",
      "33 of 340 articles cleaned.\r",
      "34 of 340 articles cleaned.\r",
      "35 of 340 articles cleaned.\r",
      "36 of 340 articles cleaned.\r",
      "37 of 340 articles cleaned.\r",
      "38 of 340 articles cleaned.\r",
      "39 of 340 articles cleaned.\r",
      "40 of 340 articles cleaned.\r",
      "41 of 340 articles cleaned.\r",
      "42 of 340 articles cleaned.\r",
      "43 of 340 articles cleaned.\r",
      "44 of 340 articles cleaned.\r",
      "45 of 340 articles cleaned.\r",
      "46 of 340 articles cleaned.\r",
      "47 of 340 articles cleaned.\r",
      "48 of 340 articles cleaned.\r",
      "49 of 340 articles cleaned.\r",
      "50 of 340 articles cleaned.\r",
      "51 of 340 articles cleaned.\r",
      "52 of 340 articles cleaned.\r",
      "53 of 340 articles cleaned.\r",
      "54 of 340 articles cleaned.\r",
      "55 of 340 articles cleaned.\r",
      "56 of 340 articles cleaned.\r",
      "57 of 340 articles cleaned.\r",
      "58 of 340 articles cleaned.\r",
      "59 of 340 articles cleaned.\r",
      "60 of 340 articles cleaned.\r",
      "61 of 340 articles cleaned.\r",
      "62 of 340 articles cleaned.\r",
      "63 of 340 articles cleaned.\r",
      "64 of 340 articles cleaned.\r",
      "65 of 340 articles cleaned.\r",
      "66 of 340 articles cleaned.\r",
      "67 of 340 articles cleaned.\r",
      "68 of 340 articles cleaned.\r",
      "69 of 340 articles cleaned.\r",
      "70 of 340 articles cleaned.\r",
      "71 of 340 articles cleaned.\r",
      "72 of 340 articles cleaned.\r",
      "73 of 340 articles cleaned.\r",
      "74 of 340 articles cleaned.\r",
      "75 of 340 articles cleaned.\r",
      "76 of 340 articles cleaned.\r",
      "77 of 340 articles cleaned.\r",
      "78 of 340 articles cleaned.\r",
      "79 of 340 articles cleaned.\r",
      "80 of 340 articles cleaned.\r",
      "81 of 340 articles cleaned.\r",
      "82 of 340 articles cleaned.\r",
      "83 of 340 articles cleaned.\r",
      "84 of 340 articles cleaned.\r",
      "85 of 340 articles cleaned.\r",
      "86 of 340 articles cleaned.\r",
      "87 of 340 articles cleaned.\r",
      "88 of 340 articles cleaned.\r",
      "89 of 340 articles cleaned.\r",
      "90 of 340 articles cleaned.\r",
      "91 of 340 articles cleaned.\r",
      "92 of 340 articles cleaned.\r",
      "93 of 340 articles cleaned.\r",
      "94 of 340 articles cleaned.\r",
      "95 of 340 articles cleaned.\r",
      "96 of 340 articles cleaned.\r",
      "97 of 340 articles cleaned.\r",
      "98 of 340 articles cleaned.\r",
      "99 of 340 articles cleaned.\r",
      "100 of 340 articles cleaned.\r",
      "101 of 340 articles cleaned.\r",
      "102 of 340 articles cleaned.\r",
      "103 of 340 articles cleaned.\r",
      "104 of 340 articles cleaned.\r",
      "105 of 340 articles cleaned.\r",
      "106 of 340 articles cleaned.\r",
      "107 of 340 articles cleaned.\r",
      "108 of 340 articles cleaned.\r",
      "109 of 340 articles cleaned.\r",
      "110 of 340 articles cleaned.\r",
      "111 of 340 articles cleaned.\r",
      "112 of 340 articles cleaned.\r",
      "113 of 340 articles cleaned.\r",
      "114 of 340 articles cleaned.\r",
      "115 of 340 articles cleaned.\r",
      "116 of 340 articles cleaned.\r",
      "117 of 340 articles cleaned.\r",
      "118 of 340 articles cleaned.\r",
      "119 of 340 articles cleaned.\r",
      "120 of 340 articles cleaned.\r",
      "121 of 340 articles cleaned.\r",
      "122 of 340 articles cleaned.\r",
      "123 of 340 articles cleaned.\r",
      "124 of 340 articles cleaned.\r",
      "125 of 340 articles cleaned.\r",
      "126 of 340 articles cleaned.\r",
      "127 of 340 articles cleaned.\r",
      "128 of 340 articles cleaned.\r",
      "129 of 340 articles cleaned.\r",
      "130 of 340 articles cleaned.\r",
      "131 of 340 articles cleaned.\r",
      "132 of 340 articles cleaned.\r",
      "133 of 340 articles cleaned.\r",
      "134 of 340 articles cleaned.\r",
      "135 of 340 articles cleaned.\r",
      "136 of 340 articles cleaned.\r",
      "137 of 340 articles cleaned.\r",
      "138 of 340 articles cleaned.\r",
      "139 of 340 articles cleaned.\r",
      "140 of 340 articles cleaned.\r",
      "141 of 340 articles cleaned.\r",
      "142 of 340 articles cleaned.\r",
      "143 of 340 articles cleaned.\r",
      "144 of 340 articles cleaned.\r",
      "145 of 340 articles cleaned.\r",
      "146 of 340 articles cleaned.\r",
      "147 of 340 articles cleaned.\r",
      "148 of 340 articles cleaned.\r",
      "149 of 340 articles cleaned.\r",
      "150 of 340 articles cleaned.\r",
      "151 of 340 articles cleaned.\r",
      "152 of 340 articles cleaned.\r",
      "153 of 340 articles cleaned.\r",
      "154 of 340 articles cleaned.\r",
      "155 of 340 articles cleaned.\r",
      "156 of 340 articles cleaned.\r",
      "157 of 340 articles cleaned.\r",
      "158 of 340 articles cleaned.\r",
      "159 of 340 articles cleaned.\r",
      "160 of 340 articles cleaned.\r",
      "161 of 340 articles cleaned.\r",
      "162 of 340 articles cleaned.\r",
      "163 of 340 articles cleaned.\r",
      "164 of 340 articles cleaned.\r",
      "165 of 340 articles cleaned.\r",
      "166 of 340 articles cleaned.\r",
      "167 of 340 articles cleaned.\r",
      "168 of 340 articles cleaned.\r",
      "169 of 340 articles cleaned.\r",
      "170 of 340 articles cleaned.\r",
      "171 of 340 articles cleaned.\r",
      "172 of 340 articles cleaned.\r",
      "173 of 340 articles cleaned.\r",
      "174 of 340 articles cleaned.\r",
      "175 of 340 articles cleaned.\r",
      "176 of 340 articles cleaned.\r",
      "177 of 340 articles cleaned.\r",
      "178 of 340 articles cleaned.\r",
      "179 of 340 articles cleaned.\r",
      "180 of 340 articles cleaned.\r",
      "181 of 340 articles cleaned.\r",
      "182 of 340 articles cleaned.\r",
      "183 of 340 articles cleaned.\r",
      "184 of 340 articles cleaned.\r",
      "185 of 340 articles cleaned.\r",
      "186 of 340 articles cleaned.\r",
      "187 of 340 articles cleaned.\r",
      "188 of 340 articles cleaned.\r",
      "189 of 340 articles cleaned.\r",
      "190 of 340 articles cleaned.\r",
      "191 of 340 articles cleaned.\r",
      "192 of 340 articles cleaned.\r",
      "193 of 340 articles cleaned.\r",
      "194 of 340 articles cleaned.\r",
      "195 of 340 articles cleaned.\r",
      "196 of 340 articles cleaned.\r",
      "197 of 340 articles cleaned.\r",
      "198 of 340 articles cleaned.\r",
      "199 of 340 articles cleaned.\r",
      "200 of 340 articles cleaned.\r",
      "201 of 340 articles cleaned.\r",
      "202 of 340 articles cleaned.\r",
      "203 of 340 articles cleaned.\r",
      "204 of 340 articles cleaned.\r",
      "205 of 340 articles cleaned.\r",
      "206 of 340 articles cleaned.\r",
      "207 of 340 articles cleaned.\r",
      "208 of 340 articles cleaned.\r",
      "209 of 340 articles cleaned.\r",
      "210 of 340 articles cleaned.\r",
      "211 of 340 articles cleaned.\r",
      "212 of 340 articles cleaned.\r",
      "213 of 340 articles cleaned.\r",
      "214 of 340 articles cleaned.\r",
      "215 of 340 articles cleaned.\r",
      "216 of 340 articles cleaned.\r",
      "217 of 340 articles cleaned.\r",
      "218 of 340 articles cleaned.\r",
      "219 of 340 articles cleaned.\r",
      "220 of 340 articles cleaned.\r",
      "221 of 340 articles cleaned.\r",
      "222 of 340 articles cleaned.\r",
      "223 of 340 articles cleaned.\r",
      "224 of 340 articles cleaned.\r",
      "225 of 340 articles cleaned.\r",
      "226 of 340 articles cleaned.\r",
      "227 of 340 articles cleaned.\r",
      "228 of 340 articles cleaned.\r",
      "229 of 340 articles cleaned.\r",
      "230 of 340 articles cleaned.\r",
      "231 of 340 articles cleaned.\r",
      "232 of 340 articles cleaned.\r",
      "233 of 340 articles cleaned.\r",
      "234 of 340 articles cleaned.\r",
      "235 of 340 articles cleaned.\r",
      "236 of 340 articles cleaned.\r",
      "237 of 340 articles cleaned.\r",
      "238 of 340 articles cleaned.\r",
      "239 of 340 articles cleaned.\r",
      "240 of 340 articles cleaned.\r",
      "241 of 340 articles cleaned.\r",
      "242 of 340 articles cleaned.\r",
      "243 of 340 articles cleaned.\r",
      "244 of 340 articles cleaned.\r",
      "245 of 340 articles cleaned.\r",
      "246 of 340 articles cleaned.\r",
      "247 of 340 articles cleaned.\r",
      "248 of 340 articles cleaned.\r",
      "249 of 340 articles cleaned.\r",
      "250 of 340 articles cleaned.\r",
      "251 of 340 articles cleaned.\r",
      "252 of 340 articles cleaned.\r",
      "253 of 340 articles cleaned.\r",
      "254 of 340 articles cleaned.\r",
      "255 of 340 articles cleaned.\r",
      "256 of 340 articles cleaned.\r",
      "257 of 340 articles cleaned.\r",
      "258 of 340 articles cleaned.\r",
      "259 of 340 articles cleaned.\r",
      "260 of 340 articles cleaned.\r",
      "261 of 340 articles cleaned.\r",
      "262 of 340 articles cleaned.\r",
      "263 of 340 articles cleaned.\r",
      "264 of 340 articles cleaned.\r",
      "265 of 340 articles cleaned.\r",
      "266 of 340 articles cleaned.\r",
      "267 of 340 articles cleaned.\r",
      "268 of 340 articles cleaned.\r",
      "269 of 340 articles cleaned.\r",
      "270 of 340 articles cleaned.\r",
      "271 of 340 articles cleaned.\r",
      "272 of 340 articles cleaned.\r",
      "273 of 340 articles cleaned.\r",
      "274 of 340 articles cleaned.\r",
      "275 of 340 articles cleaned.\r",
      "276 of 340 articles cleaned.\r",
      "277 of 340 articles cleaned.\r",
      "278 of 340 articles cleaned.\r",
      "279 of 340 articles cleaned.\r",
      "280 of 340 articles cleaned.\r",
      "281 of 340 articles cleaned.\r",
      "282 of 340 articles cleaned.\r",
      "283 of 340 articles cleaned.\r",
      "284 of 340 articles cleaned.\r",
      "285 of 340 articles cleaned.\r",
      "286 of 340 articles cleaned.\r",
      "287 of 340 articles cleaned.\r",
      "288 of 340 articles cleaned.\r",
      "289 of 340 articles cleaned.\r",
      "290 of 340 articles cleaned.\r",
      "291 of 340 articles cleaned.\r",
      "292 of 340 articles cleaned.\r",
      "293 of 340 articles cleaned.\r",
      "294 of 340 articles cleaned.\r",
      "295 of 340 articles cleaned.\r",
      "296 of 340 articles cleaned.\r",
      "297 of 340 articles cleaned.\r",
      "298 of 340 articles cleaned.\r",
      "299 of 340 articles cleaned.\r",
      "300 of 340 articles cleaned.\r",
      "301 of 340 articles cleaned.\r",
      "302 of 340 articles cleaned.\r",
      "303 of 340 articles cleaned.\r",
      "304 of 340 articles cleaned.\r",
      "305 of 340 articles cleaned.\r",
      "306 of 340 articles cleaned.\r",
      "307 of 340 articles cleaned.\r",
      "308 of 340 articles cleaned.\r",
      "309 of 340 articles cleaned.\r",
      "310 of 340 articles cleaned.\r",
      "311 of 340 articles cleaned.\r",
      "312 of 340 articles cleaned.\r",
      "313 of 340 articles cleaned.\r",
      "314 of 340 articles cleaned.\r",
      "315 of 340 articles cleaned.\r",
      "316 of 340 articles cleaned.\r",
      "317 of 340 articles cleaned.\r",
      "318 of 340 articles cleaned.\r",
      "319 of 340 articles cleaned.\r",
      "320 of 340 articles cleaned.\r",
      "321 of 340 articles cleaned.\r",
      "322 of 340 articles cleaned.\r",
      "323 of 340 articles cleaned.\r",
      "324 of 340 articles cleaned.\r",
      "325 of 340 articles cleaned.\r",
      "326 of 340 articles cleaned.\r",
      "327 of 340 articles cleaned.\r",
      "328 of 340 articles cleaned.\r",
      "329 of 340 articles cleaned.\r",
      "330 of 340 articles cleaned.\r",
      "331 of 340 articles cleaned.\r",
      "332 of 340 articles cleaned.\r",
      "333 of 340 articles cleaned.\r",
      "334 of 340 articles cleaned.\r",
      "335 of 340 articles cleaned.\r",
      "336 of 340 articles cleaned.\r",
      "337 of 340 articles cleaned.\r",
      "338 of 340 articles cleaned.\r",
      "339 of 340 articles cleaned.\r",
      "340 of 340 articles cleaned.\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Code</th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AASKK37</td>\n",
       "      <td>22</td>\n",
       "      <td>set whether unique element set .</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AASKK288</td>\n",
       "      <td>20</td>\n",
       "      <td>data oversampling .</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AASKK108</td>\n",
       "      <td>10</td>\n",
       "      <td>python search list list .</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AASKK171</td>\n",
       "      <td>16</td>\n",
       "      <td>panda pivot table .</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AASKK19</td>\n",
       "      <td>18</td>\n",
       "      <td>ai machine learning big data computing big dat...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic_Code Category                                               Text  Code\n",
       "0    AASKK37       22                  set whether unique element set .     22\n",
       "1   AASKK288       20                               data oversampling .     20\n",
       "2   AASKK108       10                         python search list list .     10\n",
       "3   AASKK171       16                               panda pivot table .     16\n",
       "4    AASKK19       18  ai machine learning big data computing big dat...    18"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = []\n",
    "n = data_df['Text'].shape[0]\n",
    "col_number = data_df.columns.get_loc('Text')\n",
    "stopWords = set(stopwords.words('english'))\n",
    "data_cleaned = data_df.copy()\n",
    "for i in range(n):\n",
    "    temp_string,idx_string = cleanString(data_df.iloc[i,col_number],stopWords)\n",
    "    articles.append(temp_string)\n",
    "    print(str(i+1)+' of '+str(n)+\" articles cleaned.\",end='\\r')\n",
    "    \n",
    "data_cleaned.loc[:,'Text'] = pd.Series(articles,index=data_df.index)\n",
    "data_cleaned.loc[:,'Category'] = pd.Categorical(data_cleaned.Category)\n",
    "data_cleaned['Code'] = data_cleaned.Category.cat.codes\n",
    "categoryToCode = dict( enumerate(data_cleaned['Category'].cat.categories))\n",
    "\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19, 20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25}\n",
      "Total:  340\n",
      "Training:  272 , Percentage:  0.8\n",
      "Validation:  29 , Percentage:  0.08529411764705883\n",
      "Test: 39 , Percentage:  0.11470588235294117\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split Pandas Dataframe into train, validation and testset.\n",
    "Convert data to keras conforming form\n",
    "\"\"\"\n",
    "\n",
    "print(categoryToCode)\n",
    "train, validation, test = split_df(data_cleaned, 'Code',0.8,0.1,0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Code</th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>AASKK102</td>\n",
       "      <td>10</td>\n",
       "      <td>write list list file .</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>AASKK186</td>\n",
       "      <td>13</td>\n",
       "      <td>create 3 dimension matrix numpy like matlab .</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>AASKK207</td>\n",
       "      <td>14</td>\n",
       "      <td>outlier boxplot .</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>AASKK141</td>\n",
       "      <td>7</td>\n",
       "      <td>defining dynamic function string .</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>AASKK28</td>\n",
       "      <td>10</td>\n",
       "      <td>whether list mutable .</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>AASKK72</td>\n",
       "      <td>19</td>\n",
       "      <td>python multiline match .</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>AASKK287</td>\n",
       "      <td>2</td>\n",
       "      <td>get unique value column .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>AASKK242</td>\n",
       "      <td>1</td>\n",
       "      <td>draw correlation heatmap .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>AASKK238</td>\n",
       "      <td>23</td>\n",
       "      <td>quantile analysis python .</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>AASKK15</td>\n",
       "      <td>5</td>\n",
       "      <td>dictionary .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic_Code Category                                            Text  \\\n",
       "index                                                                       \n",
       "277     AASKK102       10                         write list list file .    \n",
       "256     AASKK186       13  create 3 dimension matrix numpy like matlab .    \n",
       "295     AASKK207       14                              outlier boxplot .    \n",
       "21      AASKK141        7             defining dynamic function string .    \n",
       "38       AASKK28       10                         whether list mutable .    \n",
       "...          ...      ...                                             ...   \n",
       "310      AASKK72       19                       python multiline match .    \n",
       "152     AASKK287        2                      get unique value column .    \n",
       "312     AASKK242        1                     draw correlation heatmap .    \n",
       "246     AASKK238       23                     quantile analysis python .    \n",
       "185      AASKK15        5                                   dictionary .    \n",
       "\n",
       "       Code  \n",
       "index        \n",
       "277      10  \n",
       "256      13  \n",
       "295      14  \n",
       "21        7  \n",
       "38       10  \n",
       "...     ...  \n",
       "310      19  \n",
       "152       2  \n",
       "312       1  \n",
       "246      23  \n",
       "185       5  \n",
       "\n",
       "[272 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Code</th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>318</td>\n",
       "      <td>AASKK128</td>\n",
       "      <td>5</td>\n",
       "      <td>dictionary python .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>AASKK184</td>\n",
       "      <td>5</td>\n",
       "      <td>key instead dict key .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>AASKK230</td>\n",
       "      <td>2</td>\n",
       "      <td>subset panda dataframe secondary index reassig...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>AASKK116</td>\n",
       "      <td>5</td>\n",
       "      <td>merge two python dictionary single expression .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>AASKK23</td>\n",
       "      <td>18</td>\n",
       "      <td>python high level language .</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>AASKK353</td>\n",
       "      <td>2</td>\n",
       "      <td>generate random dataframe .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>AASKK46</td>\n",
       "      <td>0</td>\n",
       "      <td>class python .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>AASKK312</td>\n",
       "      <td>20</td>\n",
       "      <td>generate random number python .</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>AASKK64</td>\n",
       "      <td>9</td>\n",
       "      <td>python different language .</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>AASKK07</td>\n",
       "      <td>18</td>\n",
       "      <td>python accessible .</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>AASKK77</td>\n",
       "      <td>15</td>\n",
       "      <td>csv file read python .</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>AASKK330</td>\n",
       "      <td>23</td>\n",
       "      <td>give tutorial statistical analysis python .</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>AASKK284</td>\n",
       "      <td>2</td>\n",
       "      <td>select duplicated entry .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>AASKK195</td>\n",
       "      <td>23</td>\n",
       "      <td>taking python .</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>AASKK107</td>\n",
       "      <td>10</td>\n",
       "      <td>removing duplicate list list python .</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>AASKK278</td>\n",
       "      <td>2</td>\n",
       "      <td>slice dataframe .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>AASKK92</td>\n",
       "      <td>10</td>\n",
       "      <td>sorting grouping nested list python .</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>AASKK215</td>\n",
       "      <td>17</td>\n",
       "      <td>calculate pvalue boxplot box python .</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>AASKK45</td>\n",
       "      <td>6</td>\n",
       "      <td>close file automatically use file read .</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>AASKK209</td>\n",
       "      <td>17</td>\n",
       "      <td>explaining boxplot providing reference technic...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>AASKK382</td>\n",
       "      <td>20</td>\n",
       "      <td>randomize item list place python .</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>AASKK157</td>\n",
       "      <td>7</td>\n",
       "      <td>apply function certain array element .</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>AASKK411</td>\n",
       "      <td>11</td>\n",
       "      <td>process compilation linking python .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>AASKK85</td>\n",
       "      <td>7</td>\n",
       "      <td>len function used .</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>AASKK290</td>\n",
       "      <td>12</td>\n",
       "      <td>fill missing value mean .</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>AASKK91</td>\n",
       "      <td>3</td>\n",
       "      <td>need help python datatypes .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>AASKK24</td>\n",
       "      <td>18</td>\n",
       "      <td>python used automation .</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>AASKK392</td>\n",
       "      <td>11</td>\n",
       "      <td>docstrings python .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>AASKK293</td>\n",
       "      <td>1</td>\n",
       "      <td>heatmap correlation .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic_Code Category                                               Text  \\\n",
       "index                                                                          \n",
       "318     AASKK128        5                               dictionary python .    \n",
       "27      AASKK184        5                            key instead dict key .    \n",
       "51      AASKK230        2  subset panda dataframe secondary index reassig...   \n",
       "200     AASKK116        5   merge two python dictionary single expression .    \n",
       "24       AASKK23       18                      python high level language .    \n",
       "304     AASKK353        2                       generate random dataframe .    \n",
       "138      AASKK46        0                                    class python .    \n",
       "226     AASKK312       20                   generate random number python .    \n",
       "55       AASKK64        9                       python different language .    \n",
       "40       AASKK07       18                               python accessible .    \n",
       "273      AASKK77       15                            csv file read python .    \n",
       "193     AASKK330       23       give tutorial statistical analysis python .    \n",
       "155     AASKK284        2                         select duplicated entry .    \n",
       "224     AASKK195       23                                   taking python .    \n",
       "336     AASKK107       10             removing duplicate list list python .    \n",
       "47      AASKK278        2                                 slice dataframe .    \n",
       "328      AASKK92       10             sorting grouping nested list python .    \n",
       "143     AASKK215       17             calculate pvalue boxplot box python .    \n",
       "36       AASKK45        6          close file automatically use file read .    \n",
       "116     AASKK209       17  explaining boxplot providing reference technic...   \n",
       "16      AASKK382       20                randomize item list place python .    \n",
       "215     AASKK157        7            apply function certain array element .    \n",
       "174     AASKK411       11              process compilation linking python .    \n",
       "87       AASKK85        7                               len function used .    \n",
       "154     AASKK290       12                         fill missing value mean .    \n",
       "45       AASKK91        3                      need help python datatypes .    \n",
       "293      AASKK24       18                          python used automation .    \n",
       "86      AASKK392       11                               docstrings python .    \n",
       "190     AASKK293        1                             heatmap correlation .    \n",
       "\n",
       "       Code  \n",
       "index        \n",
       "318       5  \n",
       "27        5  \n",
       "51        2  \n",
       "200       5  \n",
       "24       18  \n",
       "304       2  \n",
       "138       0  \n",
       "226      20  \n",
       "55        9  \n",
       "40       18  \n",
       "273      15  \n",
       "193      23  \n",
       "155       2  \n",
       "224      23  \n",
       "336      10  \n",
       "47        2  \n",
       "328      10  \n",
       "143      17  \n",
       "36        6  \n",
       "116      17  \n",
       "16       20  \n",
       "215       7  \n",
       "174      11  \n",
       "87        7  \n",
       "154      12  \n",
       "45        3  \n",
       "293      18  \n",
       "86       11  \n",
       "190       1  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Code</th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>AASKK317</td>\n",
       "      <td>20</td>\n",
       "      <td>poisson distribution python .</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>AASKK31</td>\n",
       "      <td>25</td>\n",
       "      <td>tuple .</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>AASKK140</td>\n",
       "      <td>7</td>\n",
       "      <td>passing function multiple return value argumen...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>AASKK265</td>\n",
       "      <td>4</td>\n",
       "      <td>create sample dataframe multiindex .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>AASKK51</td>\n",
       "      <td>7</td>\n",
       "      <td>method different function .</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>AASKK150</td>\n",
       "      <td>3</td>\n",
       "      <td>apply value list python .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>AASKK255</td>\n",
       "      <td>20</td>\n",
       "      <td>sample randomly panda dataframe .</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>AASKK187</td>\n",
       "      <td>13</td>\n",
       "      <td>curious result numpy function .</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>AASKK204</td>\n",
       "      <td>17</td>\n",
       "      <td>plot boxplot panda .</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>AASKK338</td>\n",
       "      <td>23</td>\n",
       "      <td>get memory usage statitsics dataframe .</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>AASKK391</td>\n",
       "      <td>11</td>\n",
       "      <td>comment multiple line python .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>AASKK322</td>\n",
       "      <td>18</td>\n",
       "      <td>multi line comment python .</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>AASKK331</td>\n",
       "      <td>18</td>\n",
       "      <td>give link python .</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>AASKK125</td>\n",
       "      <td>5</td>\n",
       "      <td>pythonic way reverse nested dictionary .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>AASKK154</td>\n",
       "      <td>0</td>\n",
       "      <td>create custom dataobjects python .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>AASKK126</td>\n",
       "      <td>5</td>\n",
       "      <td>merging python dictionary .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>AASKK198</td>\n",
       "      <td>1</td>\n",
       "      <td>labelencoding panda dataframe using sklearn la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>AASKK114</td>\n",
       "      <td>10</td>\n",
       "      <td>compare two list python return match .</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>AASKK277</td>\n",
       "      <td>10</td>\n",
       "      <td>slice list .</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>AASKK344</td>\n",
       "      <td>8</td>\n",
       "      <td>groupby one column panda .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>AASKK333</td>\n",
       "      <td>18</td>\n",
       "      <td>give link lecture python understanding .</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>AASKK226</td>\n",
       "      <td>21</td>\n",
       "      <td>panda merge column single time series .</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>AASKK122</td>\n",
       "      <td>5</td>\n",
       "      <td>sorting list list dictionary .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>AASKK100</td>\n",
       "      <td>10</td>\n",
       "      <td>clearing python list .</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>AASKK172</td>\n",
       "      <td>16</td>\n",
       "      <td>panda qcut method .</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>AASKK69</td>\n",
       "      <td>7</td>\n",
       "      <td>best way return multiple value function python .</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>AASKK42</td>\n",
       "      <td>6</td>\n",
       "      <td>file read operation .</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>AASKK402</td>\n",
       "      <td>11</td>\n",
       "      <td>python package .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>AASKK167</td>\n",
       "      <td>9</td>\n",
       "      <td>python unique method identifier .</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>AASKK399</td>\n",
       "      <td>11</td>\n",
       "      <td>len .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>AASKK247</td>\n",
       "      <td>2</td>\n",
       "      <td>apply boolean mask dataframe .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>AASKK335</td>\n",
       "      <td>2</td>\n",
       "      <td>change type numeric panda .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>AASKK336</td>\n",
       "      <td>2</td>\n",
       "      <td>purpose astype panda .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>AASKK224</td>\n",
       "      <td>12</td>\n",
       "      <td>remove missing value .</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>AASKK38</td>\n",
       "      <td>22</td>\n",
       "      <td>whether set mutable .</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>AASKK14</td>\n",
       "      <td>24</td>\n",
       "      <td>string .</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>AASKK217</td>\n",
       "      <td>2</td>\n",
       "      <td>find starting ending column name .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>AASKK305</td>\n",
       "      <td>15</td>\n",
       "      <td>read csv file python .</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>AASKK342</td>\n",
       "      <td>17</td>\n",
       "      <td>basic data graph panda .</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic_Code Category                                               Text  \\\n",
       "72    AASKK317       20                     poisson distribution python .    \n",
       "59     AASKK31       25                                           tuple .    \n",
       "23    AASKK140        7  passing function multiple return value argumen...   \n",
       "268   AASKK265        4              create sample dataframe multiindex .    \n",
       "203    AASKK51        7                       method different function .    \n",
       "150   AASKK150        3                         apply value list python .    \n",
       "82    AASKK255       20                 sample randomly panda dataframe .    \n",
       "233   AASKK187       13                   curious result numpy function .    \n",
       "327   AASKK204       17                              plot boxplot panda .    \n",
       "22    AASKK338       23           get memory usage statitsics dataframe .    \n",
       "212   AASKK391       11                    comment multiple line python .    \n",
       "99    AASKK322       18                       multi line comment python .    \n",
       "217   AASKK331       18                                give link python .    \n",
       "60    AASKK125        5          pythonic way reverse nested dictionary .    \n",
       "176   AASKK154        0                create custom dataobjects python .    \n",
       "189   AASKK126        5                       merging python dictionary .    \n",
       "206   AASKK198        1  labelencoding panda dataframe using sklearn la...   \n",
       "183   AASKK114       10            compare two list python return match .    \n",
       "184   AASKK277       10                                      slice list .    \n",
       "161   AASKK344        8                        groupby one column panda .    \n",
       "275   AASKK333       18          give link lecture python understanding .    \n",
       "182   AASKK226       21           panda merge column single time series .    \n",
       "291   AASKK122        5                    sorting list list dictionary .    \n",
       "248   AASKK100       10                            clearing python list .    \n",
       "289   AASKK172       16                               panda qcut method .    \n",
       "69     AASKK69        7  best way return multiple value function python .    \n",
       "280    AASKK42        6                             file read operation .    \n",
       "264   AASKK402       11                                  python package .    \n",
       "157   AASKK167        9                 python unique method identifier .    \n",
       "42    AASKK399       11                                             len .    \n",
       "84    AASKK247        2                    apply boolean mask dataframe .    \n",
       "144   AASKK335        2                       change type numeric panda .    \n",
       "178   AASKK336        2                            purpose astype panda .    \n",
       "330   AASKK224       12                            remove missing value .    \n",
       "85     AASKK38       22                             whether set mutable .    \n",
       "228    AASKK14       24                                          string .    \n",
       "260   AASKK217        2                find starting ending column name .    \n",
       "300   AASKK305       15                            read csv file python .    \n",
       "10    AASKK342       17                          basic data graph panda .    \n",
       "\n",
       "     Code  \n",
       "72     20  \n",
       "59     25  \n",
       "23      7  \n",
       "268     4  \n",
       "203     7  \n",
       "150     3  \n",
       "82     20  \n",
       "233    13  \n",
       "327    17  \n",
       "22     23  \n",
       "212    11  \n",
       "99     18  \n",
       "217    18  \n",
       "60      5  \n",
       "176     0  \n",
       "189     5  \n",
       "206     1  \n",
       "183    10  \n",
       "184    10  \n",
       "161     8  \n",
       "275    18  \n",
       "182    21  \n",
       "291     5  \n",
       "248    10  \n",
       "289    16  \n",
       "69      7  \n",
       "280     6  \n",
       "264    11  \n",
       "157     9  \n",
       "42     11  \n",
       "84      2  \n",
       "144     2  \n",
       "178     2  \n",
       "330    12  \n",
       "85     22  \n",
       "228    24  \n",
       "260     2  \n",
       "300    15  \n",
       "10     17  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(data, ma = 0.6, mi = 0.0001):\n",
    "    tfidf_vectorize = TfidfVectorizer(max_df = ma, min_df = mi)\n",
    "    tfidf_data = tfidf_vectorize.fit_transform(data)\n",
    "    return tfidf_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_NaiveBayes(x_train, x_test, y_train, y_test):\n",
    "    MNB = MultinomialNB()\n",
    "    NBClassifier = MNB.fit(x_train, y_train)\n",
    "    predictions = NBClassifier.predict(x_test)\n",
    "    \n",
    "    a = accuracy_score(y_test, predictions)\n",
    "    p = precision_score(y_test, predictions, average = 'weighted')\n",
    "    r = recall_score(y_test, predictions, average = 'weighted')\n",
    "    return p, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_SVM(x_train, x_test, y_train, y_test):\n",
    "    SVM = SVC(kernel = 'linear')\n",
    "    SVMClassifier = SVM.fit(x_train, y_train)\n",
    "    predictions = SVMClassifier.predict(x_test)\n",
    "    a = accuracy_score(y_test, predictions)\n",
    "    p = precision_score(y_test, predictions, average = 'weighted')\n",
    "    r = recall_score(y_test, predictions, average = 'weighted')\n",
    "    return p, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_NN(x_train, x_test, y_train, y_test):\n",
    "    NN = MLPClassifier(solver = 'lbfgs', alpha = 0.00095, learning_rate = 'adaptive', learning_rate_init = 0.005, max_iter = 300, random_state = 0)\n",
    "    Perceptron = NN.fit(x_train, y_train)\n",
    "    predictions = Perceptron.predict(x_test)\n",
    "    a = accuracy_score(y_test, predictions)\n",
    "    p = precision_score(y_test, predictions, average = 'weighted')\n",
    "    r = recall_score(y_test, predictions, average = 'weighted')\n",
    "    return p, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_SGD(x_train, x_test, y_train, y_test):\n",
    "    SGD = SGDClassifier(loss = 'modified_huber')\n",
    "    SGDC = SGD.fit(x_train1, y_train)\n",
    "    predictions = SGDC.predict(x_test1)\n",
    "    a = accuracy_score(y_test, predictions)\n",
    "    p = precision_score(y_test, predictions, average = 'weighted')\n",
    "    r = recall_score(y_test, predictions, average = 'weighted')\n",
    "    return p, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_voting(x_train, x_test, y_train, y_test):\n",
    "    SVM = SVC(kernel = 'linear', probability = True)\n",
    "    SGD = SGDClassifier(loss = 'modified_huber')\n",
    "    EnsembleClassifier = VotingClassifier(estimators = [('sgd', SGD), ('svc', SVM)], voting = 'soft', weights = [1,1])\n",
    "    EnsembleClassifier = EnsembleClassifier.fit(x_train, y_train)\n",
    "    predictions = EnsembleClassifier.predict(x_test)\n",
    "    a = accuracy_score(y_test, predictions)\n",
    "    p = precision_score(y_test, predictions, average = 'weighted')\n",
    "    r = recall_score(y_test, predictions, average = 'weighted')\n",
    "    return p, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tfidf(test[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk.stem\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc:(english_stemmer.stem(word) for word in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['write list list file', 'creat dimens matrix numpi like matlab', 'outlier boxplot', 'defin dynam function string', 'whether list mutabl', 'method oper data class', 'correl datafram panda', 'boxplot interpret', 'set whether uniqu element set', 'uniform distibut python', 'data downsampl panda', 'creat datetim index panda', 'merg two python dictionari singl express', 'fill misss valu datatim format panda', 'multithread achiev python', 'creat custom function python', 'delet duplic dictionari list python', 'find locat item python list list', 'new instanc made class', 'generat random number python', 'dictionari', 'util panda datafram', 'creat sampl datafram datatim', 'method alway associ object class', 'creat panda seri', 'state class instanc', 'call function modul strong function name python', 'differ arithmat oper avail python', 'comment python', 'generat histogram python', 'panda', 'data oversampl', 'python advic beginn regex dictionari etc', 'differ deep shallow copi', 'type convers python', 'select column posit', 'python regular express', 'best way construct', 'python packag', 'purpos', 'lambda function', 'get particular row seri panda datafram', 'list python', 'immut datatyp', 'merg two python dictionari singl express', 'purpos oper', 'bar chart panda', 'differ aggreg size count panda', 'key dictionari', 'merg dictionari use counter', 'list whether similar array', 'add black border matplotlib ax object python', 'want understand python', 'concaten column panda', 'sort tupl contain list', 'much memori use python load list', 'chang valu none python', 'manipul list', 'calcul mean median mode function python', 'map oper', 'python scikit learn handl linear separ problem logist regress', 'python statist analysi tutori', 'index sever csv file panda record', 'plot pairplot use python', 'find match key two larg dictionari fast', 'panda cut method', 'numpi panda', 'mean would use', 'dictionari dictionari python', 'calcul statist python', 'split two nest list combin part creat two new nest list', 'plot boxplot normal distribut data', 'python panda column datafram base column name', 'tupl', 'python search list list', 'matlab differ python', 'python key select sort', 'read specif number line python', 'understand boxplot outlier', 'calcul boxplot imput data', 'python', 'panda groupbi object', 'convers panda', 'file close oper', 'new type object class', 'sort object dictionari', 'python librari', 'file delet python', 'mutabl data type', 'select column label', 'differ datatyp avail python', 'get datafram various summari statist', 'detect miss valu', 'python dictionari list somehow coupl', 'python oop concept', 'boolean index', 'chang type numer', 'row correl', 'fill miss valu median', 'find correl two column', 'read excel python', 'add extra row panda datafram', 'mutabl datatyp use python', 'simpl imput', 'pas argument function', 'python case sensit', 'excel read python', 'remov valu python array', 'tell panda pars particular column datetim object', 'slice label includ start stop label', 'use lambda function python', 'file write oper', 'key valu pair dictionari', 'python mine preprocess', 'differ mode avail python', 'indent requir python', 'oper function python', 'seaborn', 'use astyp cast object', 'generat python', 'generat random number python', 'generat random number python mani distribut', 'check dtype column', 'use', 'set', 'use boxplot find point valu like come differ condit', 'map two list singl list', 'mask base column name', 'creat random larg dataset', 'aggreg panda groupbi', 'give tutori python', 'add row panda datafram', 'chi squar result python', 'function differ method', 'mani kind random function avail python', 'need help list python', 'import function', 'generat random number python uniform distribut', 'ternari oper use python', 'python ad dictionari valu form new dictionari', 'use index datafram', 'normal distribut python', 'dictionari datatyp', 'iter list repeat element python', 'python librari name', 'whether constructor default argument', 'chang type datetim', 'way python index list contain tupl list dictionari element contain', 'open file python', 'creat dummi column multipl valu panda', 'jupyt notebook', 'import modul python', 'python differ java etc', 'convert hex string int python', 'normal uniform gaussian distribut python', 'sort object dictionari', 'method', 'differ spearman coeffici panda', 'differ python class function load', 'appli method', 'creat pivot total margin panda', 'clear variabl', 'mask datafram base index valu', 'pleas elobor numpi appli method', 'python featur data analyt', 'type cast panda datafram object', 'concaten synthes tone python', 'want know python', 'oper perform set union intersect differ', 'appli method python', 'len function', 'revers list', 'concaten two list', 'comment line', 'tensorflow opencv panda part python', 'seri', 'field python extens use', 'index list', 'panda librari', 'select list column groupbi panda', 'sort panda pivot tabl', 'differ file type read python', 'represet entiti real world', 'python intersect two list', 'explain split sub subn method modul python', 'count get uniqu element', 'usag help dir function python', 'group number panda', 'decil percentil analysi python', 'python code differ notebook', 'ai machin learn big data comput big data', 'differ python librari', 'much memori use python laod tupl', 'combin 2d array 3d array', 'panda pivot tabl', 'plot matlab function python', 'one implement whether bar boxplot', 'access datafram boolean index', 'whenev python exit memori', 'pattern match list', 'merg two python dictionari singl express', 'differ kind plot done python', 'explain inherit python exampl', 'opencv', 'descript statist describ function', 'shuffl row panda datafram', 'groupbi multipl column panda', 'get correl variabl use panda', 'python dictionari find similar', 'imput datafram', 'give lectur python learn', 'tupl mutabl', 'list', 'sampl datafram random', 'combin two list remov duplic without remov duplic origin list', 'miss valu panda', 'python ecosystem', 'ass skew boxplot', 'differ kind encod support panda', 'object repres entiti real world ident behaviour', 'fill miss valu forward fill', 'import librari python', 'capit first letter string', 'binomi distribut python', 'differ kind random number panda datafram', 'dictionari python', 'type python', 'use method variabl filter', 'split use', 'drop duplic entri', 'one hot encod dummi', 'immut datatyp use python', 'select cross section use', 'python string oper', 'python general purpos', 'subset datafram', 'concaten dictionari', 'whether python ecosystem well support', 'add valu python array', 'reproduc boxplot data point given quantil', 'constructor', 'compar massiv list dictionari python', 'whether key alway uniqu dictionari', 'python differ differ program languag', 'use map function python', 'generat random number python normal distribut', 'append two data frame panda', 'use panda datafram', 'tensorflow', 'append one datafram anoth datafram', 'name tick python matplotlib boxplot', 'seaborn', 'python datafram condit', 'put heatmap correl found', 'whether method return data', 'scipi', 'startifi sampl panda datafram', 'write onelin python code', 'convert string lowercas', 'whether function return data', 'serial panda datafram', 'python dictionari chang order nest', 'advantag numpi array offer nest python list', 'creat panda datafram object', 'python object', 'python sort list dictionari certain valu dictionari alphabet', 'order list python', 'python multilin match', 'get uniqu valu column', 'draw correl heatmap', 'quantil analysi python', 'dictionari']\n",
      "feature_name:['2d', '2d array', '2d array 3d', '3d', '3d array', 'access', 'access datafram', 'access datafram boolean', 'achiev', 'achiev python', 'ad', 'ad dictionari', 'ad dictionari valu', 'add', 'add black', 'add black bord', 'add extra', 'add extra row', 'add row', 'add row panda', 'add valu', 'add valu python', 'advantag', 'advantag numpi', 'advantag numpi array', 'advic', 'advic beginn', 'advic beginn regex', 'aggreg', 'aggreg panda', 'aggreg panda groupbi', 'aggreg s', 'aggreg size count', 'ai', 'ai machin', 'ai machin learn', 'alphabet', 'alway', 'alway associ', 'alway associ object', 'alway uniqu', 'alway uniqu dictionari', 'analysi', 'analysi python', 'analysi tutori', 'analyt', 'anoth', 'anoth datafram', 'append', 'append data', 'append data fram', 'append datafram', 'append datafram anoth', 'appli', 'appli method', 'appli method python', 'argument', 'argument funct', 'arithmat', 'arithmat op', 'arithmat oper avail', 'array', 'array 3d', 'array 3d array', 'array off', 'array offer nest', 'ass', 'ass skew', 'ass skew boxplot', 'associ', 'associ object', 'associ object class', 'astyp', 'astyp cast', 'astyp cast object', 'avail', 'avail python', 'ax', 'ax object', 'ax object python', 'bar', 'bar boxplot', 'bar chart', 'bar chart panda', 'base', 'base column', 'base index', 'base index valu', 'beginn', 'beginn regex', 'beginn regex dictionari', 'behaviour', 'best', 'best way', 'best way construct', 'big', 'big data', 'big data comput', 'binomi', 'binomi distribut', 'binomi distribut python', 'black', 'black bord', 'black border matplotlib', 'boolean', 'boolean index', 'border', 'border matplotlib', 'border matplotlib ax', 'boxplot', 'boxplot data', 'boxplot data point', 'boxplot imput', 'boxplot imput data', 'boxplot interpret', 'boxplot norm', 'boxplot normal distribut', 'boxplot outli', 'boxplot point', 'boxplot point valu', 'calcul', 'calcul boxplot', 'calcul boxplot imput', 'calcul mean', 'calcul mean median', 'calcul statist', 'calcul statist python', 'capit', 'capit lett', 'capit letter str', 'case', 'case sensit', 'cast', 'cast object', 'cast panda', 'cast panda datafram', 'certain', 'certain valu', 'certain valu dictionari', 'chang', 'chang ord', 'chang order nest', 'chang typ', 'chang type datetim', 'chang type num', 'chang valu', 'chang valu python', 'chart', 'chart panda', 'check', 'check dtyp', 'check dtype column', 'chi', 'chi squar', 'chi squar result', 'class', 'class funct', 'class function load', 'class instanc', 'clear', 'clear variabl', 'close', 'close op', 'code', 'code diff', 'code differ notebook', 'coeffici', 'coeffici panda', 'column', 'column datafram', 'column datafram bas', 'column datetim', 'column datetim object', 'column groupbi', 'column groupbi panda', 'column label', 'column multipl', 'column multipl valu', 'column panda', 'column posit', 'combin', 'combin 2d', 'combin 2d array', 'combin creat', 'combin creat new', 'combin list', 'combin list remov', 'come', 'come diff', 'come differ condit', 'comment', 'comment lin', 'comment python', 'compar', 'compar massiv', 'compar massiv list', 'comput', 'comput big', 'comput big data', 'concaten', 'concaten column', 'concaten column panda', 'concaten dictionari', 'concaten list', 'concaten synth', 'concaten synthes ton', 'concept', 'condit', 'construct', 'constructor', 'constructor default', 'constructor default argu', 'contain', 'contain list', 'contain tupl', 'contain tupl list', 'conver', 'convers panda', 'convers python', 'convert', 'convert hex', 'convert hex str', 'convert str', 'convert string lowerca', 'copi', 'correl', 'correl column', 'correl datafram', 'correl datafram panda', 'correl heatmap', 'correl variabl', 'correl variabl us', 'count', 'count panda', 'count uniqu', 'count uniqu el', 'counter', 'coupl', 'creat', 'creat custom', 'creat custom funct', 'creat datetim', 'creat datetim index', 'creat dimen', 'creat dimens matrix', 'creat dummi', 'creat dummi column', 'creat new', 'creat new nest', 'creat panda', 'creat panda datafram', 'creat panda seri', 'creat pivot', 'creat pivot tot', 'creat random', 'creat random larg', 'creat sampl', 'creat sampl datafram', 'cross', 'cross sect', 'cross section us', 'csv', 'csv file', 'csv file panda', 'custom', 'custom funct', 'custom function python', 'cut', 'cut method', 'data', 'data analyt', 'data class', 'data comput', 'data comput big', 'data downsampl', 'data downsampl panda', 'data fram', 'data frame panda', 'data oversampl', 'data point', 'data point given', 'data typ', 'datafram', 'datafram anoth', 'datafram anoth datafram', 'datafram bas', 'datafram base column', 'datafram base index', 'datafram boolean', 'datafram boolean index', 'datafram condit', 'datafram datatim', 'datafram object', 'datafram panda', 'datafram random', 'datafram vari', 'datafram various summari', 'dataset', 'datatim', 'datatim format', 'datatim format panda', 'datatyp', 'datatyp avail', 'datatyp avail python', 'datatyp us', 'datatyp use python', 'datetim', 'datetim index', 'datetim index panda', 'datetim object', 'decil', 'decil percentil', 'decil percentil analysi', 'deep', 'deep shallow', 'deep shallow copi', 'default', 'default argu', 'defin', 'defin dynam', 'defin dynam funct', 'delet', 'delet dupl', 'delet duplic dictionari', 'delet python', 'describ', 'describ funct', 'descript', 'descript statist', 'descript statist describ', 'detect', 'detect miss', 'detect miss valu', 'dictionari', 'dictionari alphabet', 'dictionari certain', 'dictionari certain valu', 'dictionari chang', 'dictionari chang ord', 'dictionari datatyp', 'dictionari dictionari', 'dictionari dictionari python', 'dictionari el', 'dictionari element contain', 'dictionari fast', 'dictionari list', 'dictionari list coupl', 'dictionari list python', 'dictionari python', 'dictionari similar', 'dictionari singl', 'dictionari singl express', 'dictionari us', 'dictionari use count', 'dictionari valu', 'dictionari valu form', 'differ', 'differ aggreg', 'differ aggreg s', 'differ arithmat', 'differ arithmat op', 'differ condit', 'differ datatyp', 'differ datatyp avail', 'differ deep', 'differ deep shallow', 'differ diff', 'differ differ program', 'differ fil', 'differ file typ', 'differ java', 'differ kind', 'differ kind encod', 'differ kind plot', 'differ kind random', 'differ method', 'differ mod', 'differ mode avail', 'differ notebook', 'differ program', 'differ program languag', 'differ python', 'differ python class', 'differ python librari', 'differ spearman', 'differ spearman coeffici', 'dimen', 'dimens matrix', 'dimens matrix numpi', 'dir', 'dir funct', 'dir function python', 'distibut', 'distibut python', 'distribut', 'distribut data', 'distribut python', 'downsampl', 'downsampl panda', 'draw', 'draw correl', 'draw correl heatmap', 'drop', 'drop dupl', 'drop duplic entri', 'dtype', 'dtype column', 'dummi', 'dummi column', 'dummi column multipl', 'duplic', 'duplic dictionari', 'duplic dictionari list', 'duplic entri', 'duplic origin', 'duplic origin list', 'duplic remov', 'duplic remov dupl', 'dynam', 'dynam funct', 'dynam function str', 'ecosystem', 'ecosystem support', 'element', 'element contain', 'element python', 'element set', 'elobor', 'elobor numpi', 'elobor numpi appli', 'encod', 'encod dummi', 'encod support', 'encod support panda', 'entiti', 'entiti r', 'entiti real world', 'entri', 'exampl', 'excel', 'excel python', 'excel read', 'excel read python', 'exit', 'exit memori', 'explain', 'explain inherit', 'explain inherit python', 'explain split', 'explain split sub', 'express', 'exten', 'extens us', 'extra', 'extra row', 'extra row panda', 'fast', 'featur', 'featur data', 'featur data analyt', 'field', 'field python', 'field python exten', 'file', 'file clos', 'file close op', 'file delet', 'file delet python', 'file panda', 'file panda record', 'file python', 'file typ', 'file type read', 'file writ', 'file write op', 'filter', 'form', 'form new', 'form new dictionari', 'format', 'format panda', 'forward', 'frame', 'frame panda', 'function', 'function avail', 'function avail python', 'function diff', 'function differ method', 'function load', 'function modul', 'function modul strong', 'function python', 'function return', 'function return data', 'function str', 'gaussian', 'gaussian distribut', 'gaussian distribut python', 'general', 'general purpo', 'generat', 'generat histogram', 'generat histogram python', 'generat python', 'generat random', 'generat random numb', 'given', 'given quantil', 'group', 'group numb', 'group number panda', 'groupbi', 'groupbi multipl', 'groupbi multipl column', 'groupbi object', 'groupbi panda', 'handl', 'handl linear', 'handl linear separ', 'heatmap', 'heatmap correl', 'help', 'help dir', 'help dir funct', 'help list', 'help list python', 'hex', 'hex str', 'hex string int', 'histogram', 'histogram python', 'hot', 'hot encod', 'hot encod dummi', 'ident', 'ident behaviour', 'immut', 'immut datatyp', 'immut datatyp us', 'implement', 'implement bar', 'implement bar boxplot', 'import', 'import funct', 'import librari', 'import librari python', 'import modul', 'import modul python', 'imput', 'imput data', 'imput datafram', 'includ', 'includ start', 'includ start stop', 'indent', 'indent requir', 'indent requir python', 'index', 'index datafram', 'index list', 'index list contain', 'index panda', 'index sev', 'index sever csv', 'index valu', 'inherit', 'inherit python', 'inherit python exampl', 'instanc', 'instanc class', 'int', 'int python', 'interpret', 'intersect', 'intersect diff', 'intersect list', 'item', 'item python', 'item python list', 'iter', 'iter list', 'iter list repeat', 'java', 'jupyt', 'jupyt notebook', 'key', 'key alway', 'key alway uniqu', 'key dictionari', 'key larg', 'key larg dictionari', 'key select', 'key select sort', 'key valu', 'key valu pair', 'kind', 'kind encod', 'kind encod support', 'kind plot', 'kind plot python', 'kind random', 'kind random funct', 'kind random numb', 'know', 'know python', 'label', 'label includ', 'label includ start', 'lambda', 'lambda funct', 'lambda function python', 'languag', 'laod', 'laod tupl', 'larg', 'larg dataset', 'larg dictionari', 'larg dictionari fast', 'learn', 'learn big', 'learn big data', 'learn handl', 'learn handl linear', 'lectur', 'lectur python', 'lectur python learn', 'len', 'len funct', 'letter', 'letter str', 'librari', 'librari python', 'like', 'like com', 'like come diff', 'like matlab', 'line', 'line python', 'linear', 'linear separ', 'linear separ problem', 'list', 'list column', 'list column groupbi', 'list combin', 'list combin creat', 'list contain', 'list contain tupl', 'list coupl', 'list dictionari', 'list dictionari certain', 'list dictionari el', 'list dictionari python', 'list fil', 'list list', 'list list fil', 'list mutabl', 'list python', 'list remov', 'list remov dupl', 'list repeat', 'list repeat el', 'list similar', 'list similar array', 'list singl', 'list singl list', 'load', 'load list', 'locat', 'locat item', 'locat item python', 'logist', 'logist regress', 'lowerca', 'machin', 'machin learn', 'machin learn big', 'mani', 'mani distribut', 'mani kind', 'mani kind random', 'manipul', 'manipul list', 'map', 'map funct', 'map function python', 'map list', 'map list singl', 'map op', 'margin', 'margin panda', 'mask', 'mask bas', 'mask base column', 'mask datafram', 'mask datafram bas', 'massiv', 'massiv list', 'massiv list dictionari', 'match', 'match key', 'match key larg', 'match list', 'matlab', 'matlab diff', 'matlab differ python', 'matlab funct', 'matlab function python', 'matplotlib', 'matplotlib ax', 'matplotlib ax object', 'matplotlib boxplot', 'matrix', 'matrix numpi', 'matrix numpi lik', 'mean', 'mean median', 'mean median mod', 'mean us', 'median', 'median mod', 'median mode funct', 'memori', 'memori us', 'memori use python', 'merg', 'merg dictionari', 'merg dictionari us', 'merg python', 'merg python dictionari', 'method', 'method alway', 'method alway associ', 'method modul', 'method modul python', 'method op', 'method oper data', 'method python', 'method return', 'method return data', 'method variabl', 'method variabl filt', 'miss', 'miss valu', 'miss valu forward', 'miss valu median', 'miss valu panda', 'misss', 'misss valu', 'misss valu datatim', 'mode', 'mode avail', 'mode avail python', 'mode funct', 'mode function python', 'modul', 'modul python', 'modul strong', 'modul strong funct', 'multilin', 'multilin match', 'multipl', 'multipl column', 'multipl column panda', 'multipl valu', 'multipl valu panda', 'multithread', 'multithread achiev', 'multithread achiev python', 'mutabl', 'mutabl data', 'mutabl data typ', 'mutabl datatyp', 'mutabl datatyp us', 'need', 'need help', 'need help list', 'nest', 'nest list', 'nest list combin', 'nest python', 'nest python list', 'new', 'new dictionari', 'new instanc', 'new instanc class', 'new nest', 'new nest list', 'new typ', 'new type object', 'normal', 'normal distribut', 'normal distribut data', 'normal distribut python', 'normal uniform', 'normal uniform gaussian', 'notebook', 'number', 'number lin', 'number line python', 'number panda', 'number panda datafram', 'number python', 'number python mani', 'number python norm', 'number python uniform', 'numer', 'numpi', 'numpi appli', 'numpi appli method', 'numpi array', 'numpi array off', 'numpi lik', 'numpi like matlab', 'numpi panda', 'object', 'object class', 'object dictionari', 'object python', 'object repr', 'object repres ent', 'offer', 'offer nest', 'offer nest python', 'onelin', 'onelin python', 'onelin python cod', 'oop', 'oop concept', 'open', 'open fil', 'open file python', 'opencv', 'opencv panda', 'opencv panda python', 'oper', 'oper avail', 'oper avail python', 'oper data', 'oper data class', 'oper funct', 'oper function python', 'oper perform', 'oper perform set', 'oper us', 'oper use python', 'order', 'order list', 'order list python', 'order nest', 'origin', 'origin list', 'outlier', 'outlier boxplot', 'oversampl', 'packag', 'pair', 'pair dictionari', 'pairplot', 'pairplot us', 'pairplot use python', 'panda', 'panda column', 'panda column datafram', 'panda cut', 'panda cut method', 'panda datafram', 'panda datafram object', 'panda groupbi', 'panda groupbi object', 'panda librari', 'panda par', 'panda pars particular', 'panda pivot', 'panda pivot tabl', 'panda python', 'panda record', 'panda seri', 'par', 'pars particular', 'pars particular column', 'particular', 'particular column', 'particular column datetim', 'particular row', 'particular row seri', 'pas', 'pas argu', 'pas argument funct', 'pattern', 'pattern match', 'pattern match list', 'percentil', 'percentil analysi', 'percentil analysi python', 'perform', 'perform set', 'perform set union', 'pivot', 'pivot tabl', 'pivot tot', 'pivot total margin', 'plea', 'pleas elobor', 'pleas elobor numpi', 'plot', 'plot boxplot', 'plot boxplot norm', 'plot matlab', 'plot matlab funct', 'plot pairplot', 'plot pairplot us', 'plot python', 'point', 'point given', 'point given quantil', 'point valu', 'point valu lik', 'posit', 'preprocess', 'problem', 'problem logist', 'problem logist regress', 'program', 'program languag', 'purpo', 'purpos op', 'python', 'python ad', 'python ad dictionari', 'python adv', 'python advic beginn', 'python array', 'python cas', 'python case sensit', 'python class', 'python class funct', 'python cod', 'python code diff', 'python datafram', 'python datafram condit', 'python dictionari', 'python dictionari chang', 'python dictionari list', 'python dictionari similar', 'python dictionari singl', 'python diff', 'python differ diff', 'python differ java', 'python ecosystem', 'python ecosystem support', 'python exampl', 'python exit', 'python exit memori', 'python exten', 'python extens us', 'python featur', 'python featur data', 'python gener', 'python general purpo', 'python index', 'python index list', 'python intersect', 'python intersect list', 'python key', 'python key select', 'python laod', 'python laod tupl', 'python learn', 'python librari', 'python list', 'python list list', 'python load', 'python load list', 'python mani', 'python mani distribut', 'python matplotlib', 'python matplotlib boxplot', 'python multilin', 'python multilin match', 'python norm', 'python normal distribut', 'python object', 'python oop', 'python oop concept', 'python packag', 'python panda', 'python panda column', 'python preprocess', 'python regular', 'python regular express', 'python scikit', 'python scikit learn', 'python search', 'python search list', 'python sort', 'python sort list', 'python statist', 'python statist analysi', 'python str', 'python string op', 'python uniform', 'python uniform distribut', 'quantil', 'quantil analysi', 'quantil analysi python', 'random', 'random funct', 'random function avail', 'random larg', 'random larg dataset', 'random numb', 'random number panda', 'random number python', 'read', 'read excel', 'read excel python', 'read python', 'read specif', 'read specif numb', 'real', 'real world', 'real world id', 'record', 'regex', 'regex dictionari', 'regress', 'regular', 'regular express', 'remov', 'remov dupl', 'remov duplic origin', 'remov duplic remov', 'remov valu', 'remov valu python', 'repeat', 'repeat el', 'repeat element python', 'repr', 'repres ent', 'repres entiti r', 'represet', 'represet ent', 'represet entiti r', 'reproduc', 'reproduc boxplot', 'reproduc boxplot data', 'requir', 'requir python', 'result', 'result python', 'return', 'return data', 'rever', 'revers list', 'row', 'row correl', 'row panda', 'row panda datafram', 'row seri', 'row seri panda', 'sampl', 'sampl datafram', 'sampl datafram datatim', 'sampl datafram random', 'sampl panda', 'sampl panda datafram', 'scikit', 'scikit learn', 'scikit learn handl', 'scipi', 'seaborn', 'search', 'search list', 'search list list', 'section', 'section us', 'select', 'select column', 'select column label', 'select column posit', 'select cross', 'select cross sect', 'select list', 'select list column', 'select sort', 'sensit', 'separ', 'separ problem', 'separ problem logist', 'seri', 'seri panda', 'seri panda datafram', 'serial', 'serial panda', 'serial panda datafram', 'set', 'set union', 'set union intersect', 'set uniqu', 'set uniqu el', 'sever', 'sever csv', 'sever csv fil', 'shallow', 'shallow copi', 'shuffl', 'shuffl row', 'shuffl row panda', 'similar', 'similar array', 'simpl', 'simpl imput', 'singl', 'singl express', 'singl list', 'size', 'size count', 'size count panda', 'skew', 'skew boxplot', 'slice', 'slice label', 'slice label includ', 'sort', 'sort list', 'sort list dictionari', 'sort object', 'sort object dictionari', 'sort panda', 'sort panda pivot', 'sort tupl', 'sort tupl contain', 'spearman', 'spearman coeffici', 'spearman coeffici panda', 'specif', 'specif numb', 'specif number lin', 'split', 'split nest', 'split nest list', 'split sub', 'split sub subn', 'split us', 'squar', 'squar result', 'squar result python', 'start', 'start stop', 'start stop label', 'startifi', 'startifi sampl', 'startifi sampl panda', 'state', 'state class', 'state class instanc', 'statist', 'statist analysi', 'statist analysi tutori', 'statist describ', 'statist describ funct', 'statist python', 'stop', 'stop label', 'string', 'string int', 'string int python', 'string lowerca', 'string op', 'strong', 'strong funct', 'strong function python', 'sub', 'sub subn', 'sub subn method', 'subn', 'subn method', 'subn method modul', 'subset', 'subset datafram', 'summari', 'summari statist', 'support', 'support panda', 'synth', 'synthes ton', 'synthes tone python', 'tabl', 'tell', 'tell panda', 'tell panda par', 'tensorflow', 'tensorflow opencv', 'tensorflow opencv panda', 'ternari', 'ternari op', 'ternari oper us', 'tick', 'tick python', 'tick python matplotlib', 'tone', 'tone python', 'total', 'total margin', 'total margin panda', 'tupl', 'tupl contain', 'tupl contain list', 'tupl list', 'tupl list dictionari', 'tupl mutabl', 'tutori', 'tutori python', 'type', 'type cast', 'type cast panda', 'type conv', 'type convers python', 'type datetim', 'type num', 'type object', 'type object class', 'type python', 'type read', 'type read python', 'understand', 'understand boxplot', 'understand boxplot outli', 'understand python', 'uniform', 'uniform distibut', 'uniform distibut python', 'uniform distribut', 'uniform gaussian', 'uniform gaussian distribut', 'union', 'union intersect', 'union intersect diff', 'uniqu', 'uniqu dictionari', 'uniqu el', 'uniqu element set', 'uniqu valu', 'uniqu valu column', 'usag', 'usag help', 'usag help dir', 'use', 'use astyp', 'use astyp cast', 'use boxplot', 'use boxplot point', 'use count', 'use index', 'use index datafram', 'use lambda', 'use lambda funct', 'use map', 'use map funct', 'use method', 'use method variabl', 'use panda', 'use panda datafram', 'use python', 'use python laod', 'use python load', 'util', 'util panda', 'util panda datafram', 'valu', 'valu column', 'valu datatim', 'valu datatim format', 'valu dictionari', 'valu dictionari alphabet', 'valu form', 'valu form new', 'valu forward', 'valu lik', 'valu like com', 'valu median', 'valu pair', 'valu pair dictionari', 'valu panda', 'valu python', 'valu python array', 'variabl', 'variabl filt', 'variabl us', 'variabl use panda', 'various', 'various summari', 'various summari statist', 'want', 'want know', 'want know python', 'want understand', 'want understand python', 'way', 'way construct', 'way python', 'way python index', 'whenev', 'whenev python', 'whenev python exit', 'world', 'world id', 'world ident behaviour', 'write', 'write list', 'write list list', 'write onelin', 'write onelin python', 'write op']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def build_tokenizer(doc):\n",
    "    token_pattern=r\"(?u)\\b\\w\\w+\\b\"\n",
    "    token_pattern = re.compile(token_pattern)\n",
    "    return token_pattern.findall(doc)\n",
    "posts_root1=[]\n",
    "for post in train[\"Text\"]:\n",
    "    #print build_tokenizer(post)\n",
    "    #print \" \".join([english_stemmer.stem(word) for word in build_tokenizer(post)])\n",
    "    posts_root1.append( \" \".join([english_stemmer.stem(word) for word in build_tokenizer(post)]) )\n",
    "\n",
    "print(posts_root1)\n",
    "#posts_root = [ \" \".join(english_stemmer.stem(word)) for doc in posts for word in build_tokenizer(doc)]\n",
    "\n",
    "vectorizer_tfidf=StemmedTfidfVectorizer(ngram_range=(1, 3),lowercase=False,min_df=1,stop_words=\"english\")\n",
    "\n",
    "\n",
    "\n",
    "x_tfidf_test=vectorizer_tfidf.fit_transform(posts_root1)\n",
    "\n",
    "print(\"feature_name:%s\" % vectorizer_tfidf.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_test(model,train,validation,vect):\n",
    "    X_train_dtm = vect.fit_transform(train[\"Text\"])\n",
    "    print ('Features: ', X_train_dtm.shape[1])\n",
    "    X_test_dtm = vect.transform(validation[\"Text\"])\n",
    "    model.fit(X_train_dtm, train[\"Code\"])\n",
    "    y_pred_class = model.predict(X_test_dtm)\n",
    "    print(\"Training Accuracy\")\n",
    "    print(model.score(X_train_dtm,train[\"Code\"]))\n",
    "    print(\"Testing Accuracy\")\n",
    "    print(model.score(X_test_dtm,validation[\"Code\"]))\n",
    "    print(classification_report(y_pred_class,validation[\"Code\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  1302\n",
      "Training Accuracy\n",
      "0.6544117647058824\n",
      "Testing Accuracy\n",
      "0.5172413793103449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.75      0.38      0.50         8\n",
      "           3       0.00      0.00      0.00         0\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       1.00      1.00      1.00         2\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       1.00      0.50      0.67         4\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       0.33      0.14      0.20         7\n",
      "          20       0.50      0.50      0.50         2\n",
      "          23       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.52        29\n",
      "   macro avg       0.41      0.34      0.37        29\n",
      "weighted avg       0.74      0.52      0.59        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KarthikeyanNatarajan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "tokenize_test(MultinomialNB(),train,validation,vectorizer_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  1302\n",
      "Training Accuracy\n",
      "0.9816176470588235\n",
      "Testing Accuracy\n",
      "0.6896551724137931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.75      1.00      0.86         3\n",
      "           3       0.00      0.00      0.00         0\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       1.00      0.50      0.67         2\n",
      "           7       1.00      0.67      0.80         3\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       1.00      0.67      0.80         3\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       1.00      1.00      1.00         1\n",
      "          15       0.00      0.00      0.00         0\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       0.67      0.29      0.40         7\n",
      "          20       0.50      0.50      0.50         2\n",
      "          23       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.69        29\n",
      "   macro avg       0.65      0.60      0.61        29\n",
      "weighted avg       0.84      0.69      0.73        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KarthikeyanNatarajan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "tokenize_test(SVC(kernel = 'linear'),vectorizer_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  1302\n",
      "Training Accuracy\n",
      "0.9963235294117647\n",
      "Testing Accuracy\n",
      "0.6896551724137931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.75      1.00      0.86         3\n",
      "           3       1.00      1.00      1.00         1\n",
      "           5       0.67      1.00      0.80         2\n",
      "           6       1.00      0.50      0.67         2\n",
      "           7       1.00      0.67      0.80         3\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       1.00      0.67      0.80         3\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       1.00      1.00      1.00         1\n",
      "          15       0.00      0.00      0.00         0\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       0.67      0.33      0.44         6\n",
      "          20       0.50      0.50      0.50         2\n",
      "          23       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.69        29\n",
      "   macro avg       0.69      0.67      0.66        29\n",
      "weighted avg       0.80      0.69      0.71        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KarthikeyanNatarajan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "mlp=MLPClassifier(solver = 'lbfgs', alpha = 0.00095, learning_rate = 'adaptive', learning_rate_init = 0.005, max_iter = 300, random_state = 0)\n",
    "tokenize_test(mlp,vectorizer_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  1302\n",
      "Training Accuracy\n",
      "0.9963235294117647\n",
      "Testing Accuracy\n",
      "0.6551724137931034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.75      1.00      0.86         3\n",
      "           3       0.00      0.00      0.00         0\n",
      "           5       0.67      1.00      0.80         2\n",
      "           6       1.00      0.50      0.67         2\n",
      "           7       1.00      0.67      0.80         3\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       1.00      0.50      0.67         4\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       1.00      1.00      1.00         1\n",
      "          15       0.00      0.00      0.00         0\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       0.67      0.33      0.44         6\n",
      "          20       0.50      0.50      0.50         2\n",
      "          23       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.66        29\n",
      "   macro avg       0.63      0.59      0.59        29\n",
      "weighted avg       0.80      0.66      0.69        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KarthikeyanNatarajan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "SGD = SGDClassifier(loss = 'modified_huber')\n",
    "tokenize_test(SGD,vectorizer_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  1302\n",
      "Training Accuracy\n",
      "0.9963235294117647\n",
      "Testing Accuracy\n",
      "0.6206896551724138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.75      1.00      0.86         3\n",
      "           3       0.00      0.00      0.00         0\n",
      "           5       0.67      1.00      0.80         2\n",
      "           6       1.00      0.50      0.67         2\n",
      "           7       1.00      0.67      0.80         3\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       1.00      0.50      0.67         4\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       1.00      1.00      1.00         1\n",
      "          15       0.00      0.00      0.00         0\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       0.67      0.29      0.40         7\n",
      "          20       0.50      0.50      0.50         2\n",
      "          23       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.62        29\n",
      "   macro avg       0.57      0.53      0.52        29\n",
      "weighted avg       0.78      0.62      0.66        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KarthikeyanNatarajan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "    SVM = SVC(kernel = 'linear', probability = True)\n",
    "    SGD = SGDClassifier(loss = 'modified_huber')\n",
    "    EnsembleClassifier = VotingClassifier(estimators = [('sgd', SGD), ('svc', SVM)], voting = 'soft', weights = [1,1])\n",
    "    tokenize_test(EnsembleClassifier,vectorizer_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
